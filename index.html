<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Immersive Audio Editor</title>
    <script src="https://cdn.jsdelivr.net/npm/tone"></script>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #000428, #004e92);
            color: white;
            text-align: center;
        }

        header {
            padding: 20px;
            background: rgba(0, 0, 0, 0.7);
            box-shadow: 0px 5px 15px rgba(0, 0, 0, 0.5);
        }

        h1 {
            margin: 0;
            font-size: 2.5rem;
        }

        p {
            margin: 10px 0 20px;
        }

        .container {
            max-width: 900px;
            margin: 30px auto;
            background: rgba(0, 0, 0, 0.8);
            padding: 20px;
            border-radius: 15px;
            box-shadow: 0px 5px 25px rgba(0, 0, 0, 0.8);
        }

        input[type="file"] {
            margin: 20px 0;
            padding: 10px;
            font-size: 1rem;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            color: #333;
        }

        .controls {
            margin: 20px 0;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 10px;
        }

        button {
            padding: 15px;
            font-size: 1rem;
            background: #004e92;
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: 0.3s ease;
            box-shadow: 0px 5px 15px rgba(0, 0, 0, 0.5);
        }

        button:hover {
            background: #000428;
        }

        audio {
            width: 100%;
            margin: 20px 0;
        }

        footer {
            margin: 20px 0;
            font-size: 0.9rem;
            color: rgba(255, 255, 255, 0.8);
        }
    </style>
</head>
<body>
    <header>
        <h1>Immersive Audio Editor</h1>
        <p>Edit your audio files with immersive and creative effects</p>
    </header>

    <div class="container">
        <input type="file" id="fileInput" accept="audio/*">
        <div class="controls">
            <button onclick="applyReverb()">Reverb</button>
            <button onclick="apply12D()">12D Audio</button>
            <button onclick="applyOutsideEffect()">Outside Headphones</button>
            <button onclick="applyBassBoost()">Bass Boost</button>
            <button onclick="applyEcho()">Echo</button>
            <button onclick="apply3DAudio()">3D Audio</button>
            <button onclick="applyRoomSimulation()">Room Simulation</button>
            <button onclick="applyConcertHall()">Concert Hall</button>
            <button onclick="applyForestAmbience()">Forest Ambience</button>
            <button onclick="applyCloseWhisper()">Close Whisper</button>
            <button onclick="applyUnderwater()">Underwater</button>
            <button onclick="applyEffects()">Apply Effects</button>
        </div>
        <audio id="audioPlayer" controls></audio>
        <button onclick="downloadAudio()">Download Edited Audio</button>
        <button onclick="stopAudio()">Stop Audio</button>
        <button onclick="pauseAudio()">Pause Audio</button>
        <button onclick="resumeAudio()">Resume Audio</button>
    </div>

    <footer>
        <p>Developed with the Web Audio API &amp; Tone.js</p>
    </footer>

    <script>
        let audioContext, source, audioBuffer, player, audioSourceNode;
        const audioPlayer = document.getElementById('audioPlayer');
        let isPlaying = false;
        let isPaused = false;
        let audioData = null;

        // Function to load and decode the uploaded audio file
        document.getElementById('fileInput').addEventListener('change', async function (event) {
            const file = event.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = async function (e) {
                audioData = e.target.result;
                audioContext = new AudioContext();
                
                // Decode the audio data from the uploaded file
                audioContext.decodeAudioData(audioData, (buffer) => {
                    audioBuffer = buffer;
                    audioSourceNode = audioContext.createBufferSource();
                    audioSourceNode.buffer = audioBuffer;
                    
                    // Connect to destination (audio output)
                    audioSourceNode.connect(audioContext.destination);
                    audioPlayer.src = URL.createObjectURL(file);
                }, (error) => {
                    console.error('Error decoding audio:', error);
                });
            };
            reader.readAsArrayBuffer(file);
        });

        // Function to stop the audio
        function stopAudio() {
            if (audioSourceNode) {
                audioSourceNode.stop();
                isPlaying = false;
                audioSourceNode = null;
            }
        }

        // Function to pause the audio
        function pauseAudio() {
            if (audioContext && isPlaying && !isPaused) {
                audioContext.suspend();
                isPaused = true;
            }
        }

        // Function to resume the audio
        function resumeAudio() {
            if (audioContext && isPaused) {
                audioContext.resume();
                isPaused = false;
            }
        }

        // Apply effects (reusing previous effect functions like Reverb, 12D, etc.)
        function applyReverb() {
            const reverb = new Tone.Reverb({ decay: 3 }).toDestination();
            audioSourceNode.connect(reverb);
        }

        function apply12D() {
            const panner = new Tone.Panner(0).toDestination();
            const loop = setInterval(() => {
                panner.pan.value = Math.sin(Date.now() * 0.002);
            }, 50);
            audioSourceNode.connect(panner);
        }

        function applyOutsideEffect() {
            const delay = new Tone.FeedbackDelay(0.4, 0.3).toDestination();
            audioSourceNode.connect(delay);
        }

        function applyBassBoost() {
            const bassEQ = new Tone.EQ3({ low: 10, mid: 0, high: -5 }).toDestination();
            audioSourceNode.connect(bassEQ);
        }

        function applyEcho() {
            const echo = new Tone.FeedbackDelay(0.6, 0.4).toDestination();
            audioSourceNode.connect(echo);
        }

        function apply3DAudio() {
            const spatial = new Tone.Listener({ position: [0, 0, 0] });
            audioSourceNode.connect(spatial);
        }

        function applyRoomSimulation() {
            const roomEffect = new Tone.Freeverb({ roomSize: 0.9 }).toDestination();
            audioSourceNode.connect(roomEffect);
        }

        function applyConcertHall() {
            const hall = new Tone.JCReverb({ roomSize: 0.8 }).toDestination();
            audioSourceNode.connect(hall);
        }

        function applyForestAmbience() {
            const ambience = new Tone.NoiseSynth({ type: 'brown' }).toDestination();
            audioSourceNode.connect(ambience);
        }

        function applyCloseWhisper() {
            const whisperEffect = new Tone.PingPongDelay(0.05, 0.8).toDestination();
            audioSourceNode.connect(whisperEffect);
        }

        function applyUnderwater() {
            const underwaterEffect = new Tone.AutoFilter({ frequency: 200 }).toDestination();
            audioSourceNode.connect(underwaterEffect);
        }

        // Apply selected effects to the audio
        function applyEffects() {
            // Reset the source node to avoid overlapping effects
            if (audioSourceNode) {
                audioSourceNode.disconnect();
            }
            
            // Recreate the audio source and apply effects
            audioSourceNode = audioContext.createBufferSource();
            audioSourceNode.buffer = audioBuffer;
            audioSourceNode.connect(audioContext.destination);
            
            // Example: Apply reverb effect as default
            applyReverb();
        }

        // Download the edited audio
        function downloadAudio() {
            if (!audioBuffer) {
                alert("Please upload an audio file first!");
                return;
            }

            const buffer = audioBuffer;
            const wavData = encodeWav(buffer); // Encoding audio to WAV
            const blob = new Blob([wavData], { type: 'audio/wav' });
            const link = document.createElement('a');
            link.href = URL.createObjectURL(blob);
            link.download = 'edited-audio.wav';
            link.click();
        }

        // Function to encode audio buffer to WAV format
        function encodeWav(buffer) {
            const sampleRate = buffer.sampleRate;
            const numChannels = buffer.numberOfChannels;
            const numFrames = buffer.length;
            const wav = new ArrayBuffer(44 + numFrames * numChannels * 2);
            const view = new DataView(wav);
            let offset = 0;

            // Write WAV header
            writeString(view, offset, 'RIFF');
            offset += 4;
            view.setUint32(offset, 36 + numFrames * numChannels * 2, true);
            offset += 4;
            writeString(view, offset, 'WAVE');
            offset += 4;
            writeString(view, offset, 'fmt ');
            offset += 4;
            view.setUint32(offset, 16, true);
            offset += 4;
            view.setUint16(offset, 1, true); // PCM format
            offset += 2;
            view.setUint16(offset, numChannels, true);
            offset += 2;
            view.setUint32(offset, sampleRate, true);
            offset += 4;
            view.setUint32(offset, sampleRate * numChannels * 2, true); // Byte rate
            offset += 4;
            view.setUint16(offset, numChannels * 2, true); // Block align
            offset += 2;
            view.setUint16(offset, 16, true); // Bits per sample
            offset += 2;
            writeString(view, offset, 'data');
            offset += 4;
            view.setUint32(offset, numFrames * numChannels * 2, true);
            offset += 4;

            // Write audio samples
            for (let channel = 0; channel < numChannels; channel++) {
                const channelData = buffer.getChannelData(channel);
                for (let i = 0; i < numFrames; i++) {
                    const sample = channelData[i] * 32767;
                    view.setInt16(offset, sample, true);
                    offset += 2;
                }
            }

            return wav;
        }

        // Function to write a string at a specified offset
        function writeString(view, offset, str) {
            for (let i = 0; i < str.length; i++) {
                view.setUint8(offset + i, str.charCodeAt(i));
            }
        }
    </script>
</body>
</html>
